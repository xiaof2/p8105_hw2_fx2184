p8105_hw2_fx2184
================
Fei
2022-10-04

``` r
subway = read_csv("NYC_Transit_Subway_Entrance_And_Exit_Data.csv")%>% janitor:: clean_names() %>% 
    mutate(
      entry = recode(entry, "YES" = "TRUE", "NO" = "FALSE" ),
      entry = as.logical(entry)
    )
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
skimr::skim(subway)
```

|                                                  |        |
|:-------------------------------------------------|:-------|
| Name                                             | subway |
| Number of rows                                   | 1868   |
| Number of columns                                | 32     |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |        |
| Column type frequency:                           |        |
| character                                        | 21     |
| logical                                          | 3      |
| numeric                                          | 8      |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |        |
| Group variables                                  | None   |

Data summary

**Variable type: character**

| skim_variable      | n_missing | complete_rate | min | max | empty | n_unique | whitespace |
|:-------------------|----------:|--------------:|----:|----:|------:|---------:|-----------:|
| division           |         0 |          1.00 |   3 |   3 |     0 |        3 |          0 |
| line               |         0 |          1.00 |   5 |  17 |     0 |       36 |          0 |
| station_name       |         0 |          1.00 |   4 |  39 |     0 |      356 |          0 |
| route1             |         0 |          1.00 |   1 |   2 |     0 |       24 |          0 |
| route2             |       848 |          0.55 |   1 |   2 |     0 |       20 |          0 |
| route3             |      1374 |          0.26 |   1 |   2 |     0 |       18 |          0 |
| route4             |      1547 |          0.17 |   1 |   1 |     0 |       13 |          0 |
| route5             |      1630 |          0.13 |   1 |   1 |     0 |       12 |          0 |
| route6             |      1741 |          0.07 |   1 |   1 |     0 |        7 |          0 |
| route7             |      1788 |          0.04 |   1 |   2 |     0 |        7 |          0 |
| entrance_type      |         0 |          1.00 |   4 |   9 |     0 |        7 |          0 |
| exit_only          |      1812 |          0.03 |   3 |   3 |     0 |        1 |          0 |
| vending            |         0 |          1.00 |   2 |   3 |     0 |        2 |          0 |
| staffing           |         0 |          1.00 |   4 |   6 |     0 |        4 |          0 |
| staff_hours        |      1828 |          0.02 |  16 |  33 |     0 |       16 |          0 |
| ada_notes          |      1793 |          0.04 |   5 |  17 |     0 |       10 |          0 |
| north_south_street |        29 |          0.98 |   4 |  23 |     0 |      307 |          0 |
| east_west_street   |        35 |          0.98 |   6 |  24 |     0 |      352 |          0 |
| corner             |        32 |          0.98 |   1 |   4 |     0 |        8 |          0 |
| station_location   |         0 |          1.00 |  20 |  23 |     0 |      472 |          0 |
| entrance_location  |         0 |          1.00 |  22 |  23 |     0 |     1857 |          0 |

**Variable type: logical**

| skim_variable  | n_missing | complete_rate | mean | count               |
|:---------------|----------:|--------------:|-----:|:--------------------|
| entry          |         0 |             1 | 0.94 | TRU: 1753, FAL: 115 |
| ada            |         0 |             1 | 0.25 | FAL: 1400, TRU: 468 |
| free_crossover |         0 |             1 | 0.78 | TRU: 1448, FAL: 420 |

**Variable type: numeric**

| skim_variable      | n_missing | complete_rate |   mean |   sd |     p0 |    p25 |    p50 |    p75 |   p100 | hist  |
|:-------------------|----------:|--------------:|-------:|-----:|-------:|-------:|-------:|-------:|-------:|:------|
| station_latitude   |         0 |          1.00 |  40.73 | 0.07 |  40.58 |  40.69 |  40.73 |  40.77 |  40.90 | ▂▅▇▃▂ |
| station_longitude  |         0 |          1.00 | -73.94 | 0.06 | -74.03 | -73.99 | -73.96 | -73.91 | -73.76 | ▇▆▃▂▁ |
| route8             |      1820 |          0.03 |   2.98 | 1.94 |   1.00 |   1.00 |   4.00 |   5.00 |   5.00 | ▇▁▁▂▇ |
| route9             |      1840 |          0.01 |   2.54 | 1.17 |   2.00 |   2.00 |   2.00 |   2.00 |   5.00 | ▇▁▁▁▂ |
| route10            |      1845 |          0.01 |   3.00 | 0.00 |   3.00 |   3.00 |   3.00 |   3.00 |   3.00 | ▁▁▇▁▁ |
| route11            |      1845 |          0.01 |   7.00 | 0.00 |   7.00 |   7.00 |   7.00 |   7.00 |   7.00 | ▁▁▇▁▁ |
| entrance_latitude  |         0 |          1.00 |  40.73 | 0.07 |  40.58 |  40.69 |  40.73 |  40.77 |  40.90 | ▂▅▇▃▂ |
| entrance_longitude |         0 |          1.00 | -73.86 | 3.42 | -74.03 | -73.99 | -73.96 | -73.91 |  73.99 | ▇▁▁▁▁ |

-   The dataset NYC Transit Subway Entrance and Exit Data contains 1868
    x 32 variables with name: division, line, station_name,
    station_latitude, station_longitude, route1, route2, route3, route4,
    route5, route6, route7, route8, route9, route10, route11,
    entrance_type, entry, exit_only, vending, staffing, staff_hours,
    ada, ada_notes, free_crossover, north_south_street,
    east_west_street, corner, entrance_latitude, entrance_longitude,
    station_location, entrance_location.

-   The data describes the 11 different routes of NYC. For now, I only
    imported this data and change the variable type of entry to logical
    variable.

-   This data is not a tidy data due to redundancy.

# How many distinct stations are there?

``` r
# How many distinct stations are there? 
distinct_stations = distinct(subway, line, station_name, .keep_all = TRUE)
# How many stations are ADA compliant?
ada = distinct(subway, line, station_name, .keep_all = TRUE) %>%  filter(ada)
# What proportion of station entrances / exits without vending allow entrance?
proportion = nrow(filter(subway, vending == "NO", entry == "TRUE"))/nrow(filter(subway, vending == "NO"))
show(proportion)
```

    ## [1] 0.3770492

``` r
#How many distinct stations serve the A train? 
subway_wide = subway %>%
  mutate(route8 = as.character(route8),
         route9 = as.character(route9),
         route10 = as.character(route10),
         route11 = as.character(route11)) %>%
  pivot_longer(route1:route11, names_to = "route_number", values_to = "route_name")

distinct_A = distinct(subway_wide, line, station_name, .keep_all = TRUE) %>% filter(route_name == "A" )

# Of the stations that serve the A train, how many are ADA compliant?
distinct_A_ada = distinct(subway_wide, line, station_name, .keep_all = TRUE) %>% filter(ada & route_name == "A")
```

-   Answer: there are 465 distinct stations in this dataset.
-   Answer: There are 84 stations are ADA compliant.
-   Answer: The proportion of station entrances / exits without vending
    allow entrance is 0.3770492.
-   Answer: there are 60distinct station serve the A train.
-   Answer: there are 17 distinct station serve A train and ada
    compliant.

# Problem 2

Read and clean the Mr. Trash Wheel sheet:

specify the sheet in the Excel file and to omit non-data entries (rows
with notes / figures; columns containing notes) using arguments in
read_excel use reasonable variable names omit rows that do not include
dumpster-specific data round the number of sports balls to the nearest
integer and converts the result to an integer variable (using
as.integer) Use a similar process to import, clean, and organize the
data for Professor Trash Wheel, and combine this with the Mr. Trash
Wheel dataset to produce a single tidy dataset. To keep track of which
Trash Wheel is which, you may need to add an additional variable to both
datasets before combining.

Write a paragraph about these data; you are encouraged to use inline R.
Be sure to note the number of observations in the resulting dataset, and
give examples of key variables. For available data, what was the total
weight of trash collected by Professor Trash Wheel? What was the total
number of sports balls collected by Mr. Trash Wheel in 2020?

## Mr. Trash Wheel dataset

``` r
Mr_Trash_Wheel = read_excel("Trash Wheel Collection Data.xlsx", 
    sheet = "Mr. Trash Wheel") %>% 
    janitor:: clean_names() %>% 
    filter(dumpster !='Grand Total') %>% 
    drop_na(dumpster) %>% 
    rename("weight(tons)" = "weight_tons", "volume(cubic yards)" = "volume_cubic_yards") %>% 
    mutate(sports_balls = as.integer(round(sports_balls,0))) %>% 
    select(-x15, -x16)
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

## Professor Trash Wheel

``` r
Pro_Trash_Wheel = read_excel("Trash Wheel Collection Data.xlsx",
                         sheet = "Professor Trash Wheel") %>% 
    janitor:: clean_names() %>% 
    drop_na(dumpster) %>% 
    rename("weight(tons)" = "weight_tons", "volume(cubic yards)" = "volume_cubic_yards") 
```

## Merge Mr and Professor Trash Wheel

``` r
# add a new column Trash_wheel in Mr Trash Wheel in order to merge two datasets.
Mr_Trash_Wheel = mutate(Mr_Trash_Wheel, Trash_wheel = c('Mr'),
                        dumpster = as.character(dumpster))
Pro_Trash_Wheel = mutate(Pro_Trash_Wheel,dumpster = as.character(dumpster),
                         year = as.character(year),
                         Trash_wheel = c('Pro'))


# merge the two datasets 
Mr_and_Pro = Mr_Trash_Wheel %>% full_join(Pro_Trash_Wheel)
```

    ## Joining, by = c("dumpster", "month", "year", "date", "weight(tons)",
    ## "volume(cubic yards)", "plastic_bottles", "polystyrene", "cigarette_butts",
    ## "glass_bottles", "grocery_bags", "chip_bags", "homes_powered", "Trash_wheel")

``` r
#sum values in column weight(tons) where Trash_wheel is equal to 'Pro'
total_weight = sum(Mr_and_Pro[which(Mr_and_Pro$Trash_wheel=='Pro'), "weight(tons)"])

#sum values in column sports_balls where Trash_wheel is equal to 'Mr'
total_balls = sum(Mr_and_Pro[which(Mr_and_Pro$Trash_wheel=='Mr'& Mr_and_Pro$year == '2020'), "sports_balls"])
```

-   `Mr_Trash_Wheel` has 547 observations and 15 variables, they are
    dumpster, month, year, date, weight(tons), volume(cubic yards),
    plastic_bottles, polystyrene, cigarette_butts, glass_bottles,
    grocery_bags, chip_bags, sports_balls, homes_powered, Trash_wheel.

-   `Pro_Trash_Wheel` has 94 observations and 14 variables, they are
    dumpster, month, year, date, weight(tons), volume(cubic yards),
    plastic_bottles, polystyrene, cigarette_butts, glass_bottles,
    grocery_bags, chip_bags, homes_powered, Trash_wheel.

-   The merged dataset called `Mr_and_Pro` has 641 observations and 15
    variables, they are dumpster, month, year, date, weight(tons),
    volume(cubic yards), plastic_bottles, polystyrene, cigarette_butts,
    glass_bottles, grocery_bags, chip_bags, sports_balls, homes_powered,
    Trash_wheel

-   The total weight of trash collected by Professor Trash Wheel is
    190.12 tons.

-   The total number of sports balls collected by Mr. Trash Wheel in
    2020 is 856.

# Problem 3 （Fivethirtyeight datasets)

# Dataset: pols-month

``` r
pols_month = read.csv("~/Desktop/p8105_hw2_fx2184/fivethirtyeight_datasets/pols-month.csv") 
pols_month = pols_month %>% 
  janitor:: clean_names() %>%
  mutate(pols_month, mon = as.Date(mon)) %>% 
  mutate(year = as.integer(format(mon, format = "%Y")),
         month = as.integer(format(mon, format = "%m")),
         day = as.integer(format(mon, format = "%d"))) %>% 
  mutate(month = month.abb[month]) %>% 
  mutate(president = ifelse(prez_gop == "0", "dem","gop")) %>% 
  select(-prez_dem, -prez_gop,-day)
```

# Dataset: snp dataset

``` r
snp = read.csv("~/Desktop/p8105_hw2_fx2184/fivethirtyeight_datasets/snp.csv")  %>% 
    janitor::clean_names() %>% 
  mutate(date = lubridate::parse_date_time2(date,orders ="mdy", cutoff_2000 = 23)) %>% 
  separate(date, c("year","month","day")) %>%
  mutate(year = as.integer(year), 
         month = as.integer(month), 
         day = as.integer(day))%>%
  mutate(month = month.abb[month]) %>% 
  arrange(year,month) %>% 
  select(-day)
```

# Merge

``` r
# import the unemployment dataset 
unemployment = read.csv("~/Desktop/p8105_hw2_fx2184/fivethirtyeight_datasets/unemployment.csv") %>% 
  pivot_longer(Jan:Dec, names_to = "month", values_to = "unemployment_rate") %>% 
  janitor:: clean_names()
# merge 
pols_snp = pols_month %>% left_join(snp,Joining, by = c("year", "month"))
merge = pols_snp %>% left_join(unemployment,by = c("year", "month"))
```

-   The `pols_month` dataset has 822observations with 10 variables: mon,
    gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, year, month,
    president. The range of year is \[1947, 2015\].

-   The `snp` dataset has has 787 observations with 3 variables: year,
    month, close. The range of year is \[1950, 2015\].

-   The `unemployment` dataset has has 816observations with 3 variables:
    year, month, unemployment_rate. The range of year is \[1948, 2015\].

-   First, using the left join to merge the snp dataset into pols_month,
    the new dataset called `pols_snp` has 822 observations and
    11variables,they are mon, gov_gop, sen_gop, rep_gop, gov_dem,
    sen_dem, rep_dem, year, month, president, close. The range of year
    is \[1947, 2015\].

-   Final dataset called `merge` which merging the `unemployment`
    dataset into `pols_snp`, It contains 822 observations and 12
    variables:mon, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem,
    year, month, president, close, unemployment_rate. The range of year
    is \[1947, 2015\].
