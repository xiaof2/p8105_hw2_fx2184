p8105_hw2_fx2184
================
Fei
2022-09-29

``` r
subway = read_csv("NYC_Transit_Subway_Entrance_And_Exit_Data.csv")%>% janitor:: clean_names() %>% 
    mutate(
      entry = recode(entry, "YES" = "TRUE", "NO" = "FALSE" ),
      entry = as.logical(entry)
    )
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
skimr::skim(subway)
```

|                                                  |        |
|:-------------------------------------------------|:-------|
| Name                                             | subway |
| Number of rows                                   | 1868   |
| Number of columns                                | 32     |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |        |
| Column type frequency:                           |        |
| character                                        | 21     |
| logical                                          | 3      |
| numeric                                          | 8      |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |        |
| Group variables                                  | None   |

Data summary

**Variable type: character**

| skim_variable      | n_missing | complete_rate | min | max | empty | n_unique | whitespace |
|:-------------------|----------:|--------------:|----:|----:|------:|---------:|-----------:|
| division           |         0 |          1.00 |   3 |   3 |     0 |        3 |          0 |
| line               |         0 |          1.00 |   5 |  17 |     0 |       36 |          0 |
| station_name       |         0 |          1.00 |   4 |  39 |     0 |      356 |          0 |
| route1             |         0 |          1.00 |   1 |   2 |     0 |       24 |          0 |
| route2             |       848 |          0.55 |   1 |   2 |     0 |       20 |          0 |
| route3             |      1374 |          0.26 |   1 |   2 |     0 |       18 |          0 |
| route4             |      1547 |          0.17 |   1 |   1 |     0 |       13 |          0 |
| route5             |      1630 |          0.13 |   1 |   1 |     0 |       12 |          0 |
| route6             |      1741 |          0.07 |   1 |   1 |     0 |        7 |          0 |
| route7             |      1788 |          0.04 |   1 |   2 |     0 |        7 |          0 |
| entrance_type      |         0 |          1.00 |   4 |   9 |     0 |        7 |          0 |
| exit_only          |      1812 |          0.03 |   3 |   3 |     0 |        1 |          0 |
| vending            |         0 |          1.00 |   2 |   3 |     0 |        2 |          0 |
| staffing           |         0 |          1.00 |   4 |   6 |     0 |        4 |          0 |
| staff_hours        |      1828 |          0.02 |  16 |  33 |     0 |       16 |          0 |
| ada_notes          |      1793 |          0.04 |   5 |  17 |     0 |       10 |          0 |
| north_south_street |        29 |          0.98 |   4 |  23 |     0 |      307 |          0 |
| east_west_street   |        35 |          0.98 |   6 |  24 |     0 |      352 |          0 |
| corner             |        32 |          0.98 |   1 |   4 |     0 |        8 |          0 |
| station_location   |         0 |          1.00 |  20 |  23 |     0 |      472 |          0 |
| entrance_location  |         0 |          1.00 |  22 |  23 |     0 |     1857 |          0 |

**Variable type: logical**

| skim_variable  | n_missing | complete_rate | mean | count               |
|:---------------|----------:|--------------:|-----:|:--------------------|
| entry          |         0 |             1 | 0.94 | TRU: 1753, FAL: 115 |
| ada            |         0 |             1 | 0.25 | FAL: 1400, TRU: 468 |
| free_crossover |         0 |             1 | 0.78 | TRU: 1448, FAL: 420 |

**Variable type: numeric**

| skim_variable      | n_missing | complete_rate |   mean |   sd |     p0 |    p25 |    p50 |    p75 |   p100 | hist  |
|:-------------------|----------:|--------------:|-------:|-----:|-------:|-------:|-------:|-------:|-------:|:------|
| station_latitude   |         0 |          1.00 |  40.73 | 0.07 |  40.58 |  40.69 |  40.73 |  40.77 |  40.90 | ▂▅▇▃▂ |
| station_longitude  |         0 |          1.00 | -73.94 | 0.06 | -74.03 | -73.99 | -73.96 | -73.91 | -73.76 | ▇▆▃▂▁ |
| route8             |      1820 |          0.03 |   2.98 | 1.94 |   1.00 |   1.00 |   4.00 |   5.00 |   5.00 | ▇▁▁▂▇ |
| route9             |      1840 |          0.01 |   2.54 | 1.17 |   2.00 |   2.00 |   2.00 |   2.00 |   5.00 | ▇▁▁▁▂ |
| route10            |      1845 |          0.01 |   3.00 | 0.00 |   3.00 |   3.00 |   3.00 |   3.00 |   3.00 | ▁▁▇▁▁ |
| route11            |      1845 |          0.01 |   7.00 | 0.00 |   7.00 |   7.00 |   7.00 |   7.00 |   7.00 | ▁▁▇▁▁ |
| entrance_latitude  |         0 |          1.00 |  40.73 | 0.07 |  40.58 |  40.69 |  40.73 |  40.77 |  40.90 | ▂▅▇▃▂ |
| entrance_longitude |         0 |          1.00 | -73.86 | 3.42 | -74.03 | -73.99 | -73.96 | -73.91 |  73.99 | ▇▁▁▁▁ |

-   The dataset NYC Transit Subway Entrance and Exit Data contains 1868
    x 32 variables with name: division, line, station_name,
    station_latitude, station_longitude, route1, route2, route3, route4,
    route5, route6, route7, route8, route9, route10, route11,
    entrance_type, entry, exit_only, vending, staffing, staff_hours,
    ada, ada_notes, free_crossover, north_south_street,
    east_west_street, corner, entrance_latitude, entrance_longitude,
    station_location, entrance_location.

-   The data describes the 11 different routes of NYC. For now, I only
    imported this data and change the variable type of entry to logical
    variable.

-   This data is not a tidy data due to redundancy.

# How many distinct stations are there?

``` r
# How many distinct stations are there? 
distinct_stations = distinct(subway, line, station_name, .keep_all = TRUE)
# How many stations are ADA compliant?
ada = distinct(subway, line, station_name, .keep_all = TRUE) %>%  count(ada)
# What proportion of station entrances / exits without vending allow entrance?
proportion = nrow(filter(subway, vending == "NO", entry == "TRUE"))/nrow(filter(subway, vending == "NO"))
show(proportion)
```

    ## [1] 0.3770492

``` r
#How many distinct stations serve the A train? 
subway_wide = subway %>%
  mutate(route8 = as.character(route8),
         route9 = as.character(route9),
         route10 = as.character(route10),
         route11 = as.character(route11)) %>%
  pivot_longer(route1:route11, names_to = "route_number", values_to = "route_name")

distinct_A = distinct(subway_wide, line, station_name, .keep_all = TRUE) %>% count(route_name == "A")

# Of the stations that serve the A train, how many are ADA compliant?
distinct_A_ada = distinct(subway_wide, line, station_name, .keep_all = TRUE) %>% count(ada & route_name == "A")
```

-   Answer: there are 465 distinct stations in this dataset.
-   Answer: There are 84 stations are ADA compliant, and 381 stations
    are not ADA compliant.
-   Answer: The proportion of station entrances / exits without vending
    allow entrance is `proportion`.
-   Answer: there are 60 distinct station serve the A train.
-   Answer: there are 17 distinct station serve A train and ada
    compliant.

# Problem 2

## Mr. Trash Wheel dataset

``` r
Mr_Trash_Wheel = read_excel("~/Desktop/p8105_hw2_fx2184/Trash-Wheel-Collection-Totals-7-2020-2.xlsx",
                         sheet = "Mr. Trash Wheel") %>% 
    janitor:: clean_names() %>% 
    select(-x15,-x16,-x17) %>%
    filter(dumpster !='Grand Total') %>% 
    drop_na(dumpster) %>% 
    rename("weight(tons)" = "weight_tons", "volume(cubic yards)" = "volume_cubic_yards") %>% 
    mutate(
      sports_balls = as.integer(round(sports_balls,0)))
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`
    ## • `` -> `...17`

## import, clean, and organize the data for Professor Trash Wheel

``` r
Pro_Trash_Wheel = read_excel("~/Desktop/p8105_hw2_fx2184/Trash-Wheel-Collection-Totals-7-2020-2.xlsx",
                         sheet = "Professor Trash Wheel") %>% 
    janitor:: clean_names() %>% 
    drop_na(dumpster) %>% 
    mutate(sports_balls = as.integer(round(sports_balls,0)),
           Trash_wheel = c('Pro') )%>% 
  #add a new column called Trash_wheel in order to merge two datasets in the next step
    rename("weight(tons)" = "weight_tons", "volume(cubic yards)" = "volume_cubic_yards") 
```

## merge Mr and Professor Trash Wheel

``` r
# add a new column Trash_wheel in Mr Trash Wheel in order to merge two datasets.
Mr_Trash_Wheel = mutate(Mr_Trash_Wheel, Trash_wheel = c('Mr'))
Pro_Trash_Wheel = mutate(Pro_Trash_Wheel,dumpster = as.character(dumpster))
# 
Mr_and_Pro = Pro_Trash_Wheel %>% full_join(Mr_Trash_Wheel)
```

    ## Joining, by = c("dumpster", "month", "year", "date", "weight(tons)",
    ## "volume(cubic yards)", "plastic_bottles", "polystyrene", "cigarette_butts",
    ## "glass_bottles", "grocery_bags", "chip_bags", "sports_balls", "homes_powered",
    ## "Trash_wheel")

``` r
#sum values in column weight(tons) where Trash_wheel is equal to 'Pro'
total_weight = sum(Mr_and_Pro[which(Mr_and_Pro$Trash_wheel=='Pro'), "weight(tons)"])

#sum values in column sports_balls where Trash_wheel is equal to 'Mr'
total_balls = sum(Mr_and_Pro[which(Mr_and_Pro$Trash_wheel=='Mr'& Mr_and_Pro$year == '2020'), "sports_balls"])
```

The merged dataset Mr_and_Pro has 524 observations and 15 variables,
they are dumpster, month, year, date, weight(tons), volume(cubic yards),
plastic_bottles, polystyrene, cigarette_butts, glass_bottles,
grocery_bags, chip_bags, sports_balls, homes_powered, Trash_wheel

The total weight of trash collected by Professor Trash Wheel is 135.5
tons.

The total number of sports balls collected by Mr. Trash Wheel in 2020 is
856.

# Problem 3 （fivethirtyeight datasets)

# pols-month

``` r
pols_month = read.csv("~/Desktop/p8105_hw2_fx2184/fivethirtyeight_datasets/pols-month.csv") 
pols_month = pols_month %>% 
  janitor:: clean_names() %>%
  mutate(pols_month, mon = as.Date(mon)) %>% 
  mutate(year = as.integer(format(mon, format = "%Y")),
         month = as.integer(format(mon, format = "%m")),
         day = as.integer(format(mon, format = "%d"))) %>% 
  mutate(month = month.abb[month]) %>% 
  mutate(president = ifelse(prez_gop == "0", "dem","gop")) %>% 
  select(-prez_dem, -prez_gop,-mon)
```

# snp dataset

``` r
snp = read.csv("~/Desktop/p8105_hw2_fx2184/fivethirtyeight_datasets/snp.csv") 
snp = snp %>% 
  janitor:: clean_names() %>%
  mutate(snp, date = as.Date(date)) %>% 
  mutate(month = as.integer(format(date, format = "%Y")),
         day = as.integer(format(date, format = "%m")),
         year = as.integer(format(date, format = "%d"))) %>% 
  mutate(month = month.abb[month]) %>% 
  arrange(desc(year),desc(month)) %>% 
  select(year, month, day,close,-date)
```

# Merge

so that it can be merged with the previous datasets. This process will
involve switching from “wide” to “long” format; ensuring that key
variables have the same name; and ensuring that key variables take the
same values.

``` r
unemployment = read.csv("~/Desktop/p8105_hw2_fx2184/fivethirtyeight_datasets/unemployment.csv") %>% 
  pivot_longer(Jan:Dec, names_to = "month", values_to = "unemployment_rate") %>% 
  janitor:: clean_names()
 # mutate(unemployment, month = as.integer(month))
pols_snp = pols_month %>% left_join(snp,Joining, by = c("year", "month", "day"))
merge = pols_snp %>% left_join(unemployment,by = c("year", "month"))
```

The `pols_month` dataset has 822observations with 10 variables:
`r names(pols_month)`. The range of year is \[1947, 2015\].

The `snp` dataset has has 787observations with 4 variables:
`r names(snp)`. The range of year is \[NA, NA\].

The `unemployment` dataset has has 816observations with 3 variables:
`r names(unemployment)`. The range of year is \[1948, 2015\].

Use the left join to merge the snp dataset into pols_month, the new
dataset has 822observations and 11variables,they are
`r names(pols_snp)`. The range of year is \[1947, 2015\]. Then, merging
the `unemployment` dataset to `pols_snp`, It contains 822observations
and 12 variables:`r names(merge)`. The range of year is \[1947, 2015\].
